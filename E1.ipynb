{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "\n",
    "file = urllib.request.urlopen('https://alexip-ml.s3.amazonaws.com/stackexchange_812k.csv.gz')\n",
    "df = pd.read_csv(file, compression='gzip', header=0, sep=',', quotechar='\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>812122</th>\n",
       "      <td>279993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536604.0</td>\n",
       "      <td>@Calimo i just plotted the results of each con...</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812123</th>\n",
       "      <td>279993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536608.0</td>\n",
       "      <td>Ok, but then that's not a ROC curve, which sho...</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812124</th>\n",
       "      <td>279993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536612.0</td>\n",
       "      <td>@Calimo yes i understand. but therein lies my ...</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812125</th>\n",
       "      <td>279993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536451.0</td>\n",
       "      <td>You really want a cost function...</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812126</th>\n",
       "      <td>279993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536454.0</td>\n",
       "      <td>@Calimo it would seem so, stumbled upon `What ...</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812127</th>\n",
       "      <td>279994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536471.0</td>\n",
       "      <td>It does run, and gives very valid looking esti...</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812128</th>\n",
       "      <td>279998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536439.0</td>\n",
       "      <td>It seems to me that you are correct; the doubl...</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812129</th>\n",
       "      <td>279998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536514.0</td>\n",
       "      <td>It wouldn't be the first time a grader has mis...</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812130</th>\n",
       "      <td>279999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536802.0</td>\n",
       "      <td>The basic idea is to compare the clustering co...</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812131</th>\n",
       "      <td>279999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>542550.0</td>\n",
       "      <td>As per your other question, your data does not...</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        post_id  parent_id  comment_id  \\\n",
       "812122   279993        NaN    536604.0   \n",
       "812123   279993        NaN    536608.0   \n",
       "812124   279993        NaN    536612.0   \n",
       "812125   279993        NaN    536451.0   \n",
       "812126   279993        NaN    536454.0   \n",
       "812127   279994        NaN    536471.0   \n",
       "812128   279998        NaN    536439.0   \n",
       "812129   279998        NaN    536514.0   \n",
       "812130   279999        NaN    536802.0   \n",
       "812131   279999        NaN    542550.0   \n",
       "\n",
       "                                                     text category  \n",
       "812122  @Calimo i just plotted the results of each con...  comment  \n",
       "812123  Ok, but then that's not a ROC curve, which sho...  comment  \n",
       "812124  @Calimo yes i understand. but therein lies my ...  comment  \n",
       "812125                 You really want a cost function...  comment  \n",
       "812126  @Calimo it would seem so, stumbled upon `What ...  comment  \n",
       "812127  It does run, and gives very valid looking esti...  comment  \n",
       "812128  It seems to me that you are correct; the doubl...  comment  \n",
       "812129  It wouldn't be the first time a grader has mis...  comment  \n",
       "812130  The basic idea is to compare the clustering co...  comment  \n",
       "812131  As per your other question, your data does not...  comment  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Remove HTML tags\n",
    "df.text = df.text.str.replace('<[^<]+?>', '')\n",
    "\n",
    "# Remove Latex\n",
    "df.text = df.text.str.replace('\\\\textbf{([^}]*)}', '')\n",
    "\n",
    "# Remove rows with empty text\n",
    "filter = df[\"text\"] != \"\"\n",
    "df = df[filter]\n",
    "\n",
    "# Remove 100 words or longer\n",
    "df = df[df['text'].str.split().str.len().lt(100)]\n",
    "\n",
    "# Remove 5 words or less\n",
    "df = df[df['text'].str.split().str.len().gt(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer() \n",
    "\n",
    "# from: https://stackoverflow.com/a/54398984/773263\n",
    "def preprocess(sentence):\n",
    "    sentence=str(sentence)\n",
    "    sentence = sentence.lower()\n",
    "    sentence=sentence.replace('{html}',\"\") \n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', sentence)\n",
    "    rem_url=re.sub(r'http\\S+', '',cleantext)\n",
    "    rem_num = re.sub('[0-9]+', '', rem_url)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(rem_num)  \n",
    "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
    "    stem_words=[stemmer.stem(w) for w in filtered_words]\n",
    "    lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "\n",
    "df['cleanText']=df['text'].map(lambda s:preprocess(s)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>cleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What are some valuable Statistical Analysis op...</td>\n",
       "      <td>title</td>\n",
       "      <td>valuable statistical analysis open source proj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Assessing the significance of differences in d...</td>\n",
       "      <td>title</td>\n",
       "      <td>assessing significance differences distributions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Two Cultures: statistics vs. machine learn...</td>\n",
       "      <td>title</td>\n",
       "      <td>two cultures statistics machine learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So how many staticians *does* it take to screw...</td>\n",
       "      <td>title</td>\n",
       "      <td>many staticians take screw lightbulb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Under what conditions should Likert scales be ...</td>\n",
       "      <td>title</td>\n",
       "      <td>conditions likert scales used ordinal interval...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bayesian and frequentist reasoning in plain En...</td>\n",
       "      <td>title</td>\n",
       "      <td>bayesian frequentist reasoning plain english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finding the PDF given the CDF</td>\n",
       "      <td>title</td>\n",
       "      <td>finding pdf given cdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tools for modeling financial time series</td>\n",
       "      <td>title</td>\n",
       "      <td>tools modeling financial time series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What is the meaning of p values and t values i...</td>\n",
       "      <td>title</td>\n",
       "      <td>meaning values values statistical tests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Examples for teaching: Correlation does not me...</td>\n",
       "      <td>title</td>\n",
       "      <td>examples teaching correlation mean causation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Why do US and UK Schools Teach Different metho...</td>\n",
       "      <td>title</td>\n",
       "      <td>schools teach different methods calculating st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Can someone please explain the back-propagatio...</td>\n",
       "      <td>title</td>\n",
       "      <td>someone please explain back propagation algorithm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What R packages do you find most useful in you...</td>\n",
       "      <td>title</td>\n",
       "      <td>packages find useful daily work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Where can I find useful R tutorials with vario...</td>\n",
       "      <td>title</td>\n",
       "      <td>find useful tutorials various implementations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Robust nonparametric estimation of hazard/surv...</td>\n",
       "      <td>title</td>\n",
       "      <td>robust nonparametric estimation hazard surviva...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    post_id  parent_id  comment_id  \\\n",
       "2         3        NaN         NaN   \n",
       "3         4        NaN         NaN   \n",
       "4         6        NaN         NaN   \n",
       "6         8        NaN         NaN   \n",
       "7        10        NaN         NaN   \n",
       "10       22        NaN         NaN   \n",
       "11       23        NaN         NaN   \n",
       "12       25        NaN         NaN   \n",
       "15       31        NaN         NaN   \n",
       "17       36        NaN         NaN   \n",
       "22       54        NaN         NaN   \n",
       "23       58        NaN         NaN   \n",
       "24       73        NaN         NaN   \n",
       "25       75        NaN         NaN   \n",
       "26       93        NaN         NaN   \n",
       "\n",
       "                                                 text category  \\\n",
       "2   What are some valuable Statistical Analysis op...    title   \n",
       "3   Assessing the significance of differences in d...    title   \n",
       "4   The Two Cultures: statistics vs. machine learn...    title   \n",
       "6   So how many staticians *does* it take to screw...    title   \n",
       "7   Under what conditions should Likert scales be ...    title   \n",
       "10  Bayesian and frequentist reasoning in plain En...    title   \n",
       "11                      Finding the PDF given the CDF    title   \n",
       "12           Tools for modeling financial time series    title   \n",
       "15  What is the meaning of p values and t values i...    title   \n",
       "17  Examples for teaching: Correlation does not me...    title   \n",
       "22  Why do US and UK Schools Teach Different metho...    title   \n",
       "23  Can someone please explain the back-propagatio...    title   \n",
       "24  What R packages do you find most useful in you...    title   \n",
       "25  Where can I find useful R tutorials with vario...    title   \n",
       "26  Robust nonparametric estimation of hazard/surv...    title   \n",
       "\n",
       "                                            cleanText  \n",
       "2   valuable statistical analysis open source proj...  \n",
       "3    assessing significance differences distributions  \n",
       "4            two cultures statistics machine learning  \n",
       "6                many staticians take screw lightbulb  \n",
       "7   conditions likert scales used ordinal interval...  \n",
       "10       bayesian frequentist reasoning plain english  \n",
       "11                              finding pdf given cdf  \n",
       "12               tools modeling financial time series  \n",
       "15            meaning values values statistical tests  \n",
       "17       examples teaching correlation mean causation  \n",
       "22  schools teach different methods calculating st...  \n",
       "23  someone please explain back propagation algorithm  \n",
       "24                    packages find useful daily work  \n",
       "25      find useful tutorials various implementations  \n",
       "26  robust nonparametric estimation hazard surviva...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"clean_data.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
